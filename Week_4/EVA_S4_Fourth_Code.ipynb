{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA_S4_Fourth_Code.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxnRbGs9Jrwx",
        "colab_type": "text"
      },
      "source": [
        "# Functionality of the Code\n",
        "\n",
        "The three changes from the second code are:\n",
        "1. Addition of Dropout at Each Layer\n",
        "2. Introduction of Callbacks\n",
        "3. Change of kernel size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwBoom07NDhm",
        "colab_type": "text"
      },
      "source": [
        "# Importing the required libraries and required modules\n",
        "\n",
        "This is the vanilla coda that is executed without any additional layers other than Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmV3T8RMHe4f",
        "colab_type": "code",
        "outputId": "93fd4157-8dc4-45e4-a743-ab12283e6afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtFRE2HcIK3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Flatten, Add, BatchNormalization, Convolution2D, MaxPooling2D, Dropout\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmgElg1IN0at",
        "colab_type": "text"
      },
      "source": [
        "### Loading the MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYB6naGTMd3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSpJysQBOEsc",
        "colab_type": "code",
        "outputId": "ce91eb75-1df9-43c5-fe49-7775865842b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.imshow(x_train[20])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe63afee6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLqYK-gPO3lO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
        "xtest = x_test.reshape(x_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt_IjXh_O6lA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = xtrain.astype('float32')\n",
        "xtest = xtest.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn3t-p2HPDiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain /= 255.0\n",
        "xtest /= 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdlbHUtbPPCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytrain = np_utils.to_categorical(y_train, 10)\n",
        "ytest = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qta0SDv7Xjbg",
        "colab_type": "code",
        "outputId": "f5bf4e57-41b4-4872-96d7-ac434212f86e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(14, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(12, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 7, 7))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1))`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(14, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (7, 7))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm0M_k0jYZTg",
        "colab_type": "code",
        "outputId": "588daa28-9eee-4b26-9c26-e03e1fe320e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 26, 26, 10)        170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 11, 11, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 11, 11, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 9, 9, 14)          2030      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 9, 9, 14)          56        \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 9, 9, 14)          0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 9, 9, 14)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 7, 7, 12)          1524      \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 7, 7, 12)          48        \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 7, 7, 12)          0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 7, 7, 12)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 1, 1, 10)          5890      \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 1, 1, 10)          110       \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 11,692\n",
            "Trainable params: 11,516\n",
            "Non-trainable params: 176\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WudVHFqLQSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "    return round(0.003 * 1/(1 + 0.319 * epoch), 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGDMWxN0YaaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=Adam(lr=0.003), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KjFzNj8ZII9",
        "colab_type": "code",
        "outputId": "258252da-9291-43f5-b5f2-21350a38c720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2125
        }
      },
      "source": [
        "model.fit(xtrain, ytrain, batch_size=32, nb_epoch=30, verbose=1, validation_data=(xtest, ytest), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.4477 - acc: 0.8825 - val_loss: 0.0967 - val_acc: 0.9787\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.1991 - acc: 0.9443 - val_loss: 0.0640 - val_acc: 0.9858\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.1570 - acc: 0.9570 - val_loss: 0.0432 - val_acc: 0.9894\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.1403 - acc: 0.9619 - val_loss: 0.0340 - val_acc: 0.9909\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.1292 - acc: 0.9641 - val_loss: 0.0322 - val_acc: 0.9909\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.1217 - acc: 0.9652 - val_loss: 0.0309 - val_acc: 0.9912\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 25s 413us/step - loss: 0.1169 - acc: 0.9667 - val_loss: 0.0275 - val_acc: 0.9928\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 24s 397us/step - loss: 0.1108 - acc: 0.9689 - val_loss: 0.0281 - val_acc: 0.9930\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 25s 419us/step - loss: 0.1075 - acc: 0.9691 - val_loss: 0.0307 - val_acc: 0.9914\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 25s 411us/step - loss: 0.1033 - acc: 0.9700 - val_loss: 0.0268 - val_acc: 0.9927\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0987 - acc: 0.9711 - val_loss: 0.0255 - val_acc: 0.9931\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.1008 - acc: 0.9709 - val_loss: 0.0269 - val_acc: 0.9922\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.0984 - acc: 0.9717 - val_loss: 0.0240 - val_acc: 0.9934\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 24s 400us/step - loss: 0.0985 - acc: 0.9718 - val_loss: 0.0244 - val_acc: 0.9929\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0929 - acc: 0.9734 - val_loss: 0.0237 - val_acc: 0.9935\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 24s 396us/step - loss: 0.0939 - acc: 0.9730 - val_loss: 0.0224 - val_acc: 0.9936\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 25s 412us/step - loss: 0.0921 - acc: 0.9736 - val_loss: 0.0246 - val_acc: 0.9927\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0892 - acc: 0.9747 - val_loss: 0.0233 - val_acc: 0.9931\n",
            "Epoch 19/30\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.0908 - acc: 0.9739 - val_loss: 0.0223 - val_acc: 0.9939\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 25s 413us/step - loss: 0.0893 - acc: 0.9740 - val_loss: 0.0230 - val_acc: 0.9940\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 24s 397us/step - loss: 0.0859 - acc: 0.9752 - val_loss: 0.0228 - val_acc: 0.9935\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 25s 417us/step - loss: 0.0860 - acc: 0.9746 - val_loss: 0.0226 - val_acc: 0.9932\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.0905 - acc: 0.9737 - val_loss: 0.0227 - val_acc: 0.9930\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.0851 - acc: 0.9759 - val_loss: 0.0237 - val_acc: 0.9931\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0880 - acc: 0.9741 - val_loss: 0.0219 - val_acc: 0.9934\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.0832 - acc: 0.9752 - val_loss: 0.0223 - val_acc: 0.9933\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 25s 416us/step - loss: 0.0858 - acc: 0.9749 - val_loss: 0.0223 - val_acc: 0.9935\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.0832 - acc: 0.9759 - val_loss: 0.0221 - val_acc: 0.9937\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0772 - acc: 0.9785 - val_loss: 0.0223 - val_acc: 0.9939\n",
            "Epoch 30/30\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 25s 413us/step - loss: 0.0794 - acc: 0.9766 - val_loss: 0.0223 - val_acc: 0.9937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe5eb64aa58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24UYWhFcZJhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(xtest, ytest, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fItOD1KJgHN_",
        "colab_type": "code",
        "outputId": "361ce59a-c2c1-4809-c165-f05a80a8d069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.02227204295732081, 0.9937]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT6Nmt3HgJEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}